# MATLAB Simulated Autonomous Mobile Robot (AMR) #

This project provides a basic AMR simulated in MATLAB. The various components are:

* **Platform** : 4 Wheeled Mobile Robot; Rear wheel drive
* **Controller** : Nonlinear Back Stepping or Neural Network Controller
* **Sensor** : LIDAR
* **Navigation Algoritm** : Potential Field Navigation or Wall Follow or Bug 2
* **Localization Algorithm** : Not Implemented (Particle Filter Localization planned)


This project was completed as a requirement to MST class EE5380.

Author: Singh, Siddharth & Sengupta, Ayush

## How to run ##

Download the code and run using MATLAB.

_**Requirement**_   
This code was written in MATLAB 2015a. The code should also work with GNU Octave but is not tested.

## Explanation ##

### Controller ###
#### Nonlinear Back Stepping ####

In back stepping control, the control torque(ğœ) is a function of velocity given by:

```
  ğœ = ğµ^âˆ’1 * ğ‘€(âˆ’ğ¾ğ‘’ğ‘ + ğ‘‰Ì‡ğ‘+ â„ğ‘ + ğ‘“)

  Where,
    ğµ = Input Transformation Matrix
    ğ‘€ = Inertia Matrix
    ğ¾ = Control Gain
    ğ‘’ğ‘ = Velocity Tracking Error
    ğ‘“ = Dynamical Quantities

 ```

Our objective is to select a control torque ğœ(t) which motivates the velocity for a desired behavior.

Learn more about [Backstepping](https://en.wikipedia.org/wiki/Backstepping)

#### Neural Network Control ####

The concept of neural network control comes in when traditional control mechanism cannot correctly estimate the torque (ğœ). The drawback with neural network is that we need to train it before it can be used. For the project we are using the trace from Nonlinear Backstepping using bug2 on simple maps as initial trainer. This design supports online training which means the it keeps learning during run-time.

The implementation here is a discrete time implementation where the weight update law is given by:

```
For Hidden Layer Weights,
    ğ‘Š1(ğ‘˜ + 1) = ğ‘Š1(ğ‘˜) âˆ’ ğ›¼1*ğœ™1*(ğ‘˜)[ ğ‘¦1(ğ‘˜) + ğµ1*ğ‘˜ğ‘£*ğ‘Ÿ(ğ‘˜)]^ğ‘‡
Where,
    ğ‘Š1 = Hidden layer weight
    ğœ™1(ğ‘˜) = Activation function
    ğ›¼1=learning rate, ğµ1=constant matrix
    ğ‘¦1(ğ‘˜) = Output of previous layer
    ğ‘˜ğ‘£ = proportionality constant
    ğ‘Ÿ(ğ‘˜) = filter tracking error

For Output Layer:
    W2(ğ‘˜ + 1) = ğ‘Š2(ğ‘˜) âˆ’ ğ›¼2*ğœ™2(ğ‘˜)*ğ‘Ÿ(ğ‘˜)^ğ‘‡
Where,
    ğ‘Š2 = Output layer weights
    ğœ™2(ğ‘˜) = Activation function
    ğ›¼2 = learning rate
```
Learn more about [Discrete-time Neural Network](http://www.dlsi.ua.es/~mlf/nnafmc/pbook/node21.html)

### Sensor ###

The sensor is a simulated LIDAR sensor.

Learn more about [LIDAR](https://en.wikipedia.org/wiki/Lidar)

## Results ##

Read the original paper containing results [here](https://drive.google.com/file/d/0B7b-pBapfUqkNEF1VWczM2J2Zk0/view?usp=sharing)
